'''
Author: Abhijeet Ambekar
Date: 08/27/2023
'''
import os
import logging.config
import pandas as pd
import argparse
import dvc.api
import joblib
from process_data import process_data
from model import compute_model_metrics

params = dvc.api.params_show()
artifacts_path = params['artifacts-path']
classifier = params['model']
logging.config.fileConfig("log_config.ini")
logger = logging.getLogger()

categorical_features = [
    "workclass",
    "marital-status",
    "occupation",
    "relationship",
    "race",
    "sex",
    "native-country",
    "education"
]

model = joblib.load(os.path.join(artifacts_path, "model.pkl"))


def evaluate_slice(slice_column, slice_value):
    """This function evaluates slice data against saved model

    Args:
        slice_column (str): column name for the data slice
        slice_value (str): value of column to perform the slice
    """
    try:
        # load the data and labels artifacts generated by processing data
        test = joblib.load(os.path.join(artifacts_path, "test.joblib"))
        test[slice_column] = slice_value
        X_test, y_test = process_data(test, label='salary')

    except FileNotFoundError:
        logger.error(
            "Artifatcs not found. Please run the process data module first!!")
        return

    y_test_preds = model.predict(X_test)
    precision, recall, fbeta, accuracy = compute_model_metrics(
        y_test, y_test_preds)

    with open(os.path.join(artifacts_path, "test_output.txt"), mode="a") as fp:
        fp.write(f"Model: {classifier}, slice column: {slice_column}, " +
                 "value: {slice_value}")
        fp.write(
            f"\nAccuracy {accuracy}, Precision {precision}, recall {recall}," +
            " fbeta {fbeta}")
        fp.write("\n\n")


def slice_data_evaluate(file_path):
    """This function iterates over categories and their unique values to
        perform data slice and evaluates it against trained model

    Args:
        file_path (str): path of data file
    """
    df = pd.read_csv(file_path)
    df.columns = df.columns.str.lower().str.replace(' ', '')
    for feature in categorical_features:
        unique_values = df[feature].unique()
        for value in unique_values:
            evaluate_slice(feature, value)


if __name__ == "__main__":
    """script entry point
    """

    parser = argparse.ArgumentParser(
        description='Data slice experiment to detect the bias!')

    parser.add_argument('-f', '--file', type=str,
                        default='./data/census.csv', help='Path to data file.')

    args = parser.parse_args()
    file_path = args.file
    slice_data_evaluate(file_path)
